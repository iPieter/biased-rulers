{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM3-32GB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "# random.seed(42)\n",
    "torch.manual_seed(42) \n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "  print('No GPU available, using the CPU instead.')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertConfig\n",
    "from transformers import DistilBertTokenizer, DistilBertModel, DistilBertForMaskedLM, DistilBertConfig\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaForMaskedLM, RobertaConfig\n",
    "# from transformers import AlbertTokenizer, AlbertModel, AlbertForMaskedLM, AlbertConfig\n",
    "\n",
    "from copy import copy\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "# import pandas as pd\n",
    "import regex as re\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import glob\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 The accountant met [the janitor] and wished [him] well.\n",
      "2 The janitor met [the accountant] and wished [her] well.\n",
      "3 The assistant notified the [the chief] about a problem and asked [him] to take action.\n",
      "4 The chief notified [the assistant] and asked [her] to take note.\n",
      "5 The teacher spoke to [the carpenter] and asked [him] to fix a chair.\n",
      "6 The carpenter spoke to [the teacher] and asked [her] science questions.\n",
      "7 The assistant contacted [the lawyer] and retained [him].\n",
      "8 The lawyer contacted [\n"
     ]
    }
   ],
   "source": [
    "prodev1 = \"data/WinoBias/pro_stereotyped_type1.txt.dev.txt\"\n",
    "prodev2 = \"data/WinoBias/pro_stereotyped_type2.txt.dev.txt\"\n",
    "antidev1 = \"data/WinoBias/anti_stereotyped_type1.txt.dev.txt\"\n",
    "antidev2 = \"data/WinoBias/anti_stereotyped_type2.txt.dev.txt\"\n",
    "\n",
    "protest1 = \"data/WinoBias/pro_stereotyped_type1.txt.test.txt\"\n",
    "protest2 = \"data/WinoBias/pro_stereotyped_type2.txt.test.txt\"\n",
    "antitest1 = \"data/WinoBias/anti_stereotyped_type1.txt.test.txt\"\n",
    "antitest2 = \"data/WinoBias/anti_stereotyped_type2.txt.test.txt\"\n",
    "\n",
    "# Set male and female names for baseline tester\n",
    "male_name = 'Bob'\n",
    "female_name = 'Alice'\n",
    "\n",
    "\n",
    "# optionally can inspect the data\n",
    "# f = open(prodev1, \"r\") \n",
    "# print(f.read())\n",
    "\n",
    "# Combine dev and test set if no training is required\n",
    "\n",
    "pro1_files = [prodev1, protest1]\n",
    "pro2_files = [prodev2, protest2]\n",
    "anti1_files = [antidev1, antitest1]\n",
    "anti2_files = [antidev2, antitest2]\n",
    "types = ['pro1', 'pro2', 'anti1', 'anti2']\n",
    "for typefile in types:\n",
    "  with open(typefile+'comb.txt', \"wb\") as outfile:\n",
    "      for f in eval(typefile+'_files'):\n",
    "          with open(f, \"rb\") as infile:\n",
    "              outfile.write(infile.read())\n",
    "\n",
    "pro1 = './pro1comb.txt'\n",
    "pro2 = './pro2comb.txt'\n",
    "anti1 = './anti1comb.txt'\n",
    "anti2 = './anti2comb.txt'\n",
    "\n",
    "\n",
    "f = open(protest2, \"r\") \n",
    "print(f.read()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mAWfOFER6IDQ"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxgmdS82kFL9"
   },
   "outputs": [],
   "source": [
    "def model_loader(which_bert = 'BERT', do_PCA = False):\n",
    "  \"\"\"\n",
    "  Loads model from BERT family.\n",
    "  Input:\n",
    "  which_bert: which bert to load\n",
    "  do_PCA:     whether output of hidden layers is returned (required for doing embedding analysis)\n",
    "\n",
    "  Returns model, tokenizer corresponding to input settings\n",
    "  \"\"\"\n",
    "  which_bert = which_bert.lower()\n",
    "  if which_bert == 'roberta':\n",
    "    mask_token = '<mask>'\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base',output_hidden_states = do_PCA)\n",
    "    if do_PCA:\n",
    "      config = RobertaConfig.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "      model = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n",
    "    else:\n",
    "      model = RobertaForMaskedLM.from_pretrained('roberta-base')  \n",
    "  elif which_bert == 'distilbert':\n",
    "    mask_token = '[MASK]'\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',output_hidden_states = do_PCA)\n",
    "    if do_PCA:\n",
    "      config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\", output_hidden_states=True)\n",
    "      model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", config=config)\n",
    "    else:\n",
    "      model = DistilBertForMaskedLM.from_pretrained('distilbert-base-uncased')\n",
    "  elif which_bert == 'bert-large':\n",
    "    mask_token = '[MASK]'\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased',output_hidden_states = do_PCA)\n",
    "    if do_PCA:\n",
    "      config = BertConfig.from_pretrained(\"bert-large-uncased\", output_hidden_states=True)\n",
    "      model = BertModel.from_pretrained(\"bert-large-uncased\", config=config)\n",
    "    else:\n",
    "      model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "  elif which_bert == 'bert-base-multilingual':\n",
    "    mask_token = '[MASK]'\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased',output_hidden_states = do_PCA)\n",
    "    if do_PCA:\n",
    "      config = BertConfig.from_pretrained(\"bert-base-multilingual-uncased\", output_hidden_states=True)\n",
    "      model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\", config=config)\n",
    "    else:\n",
    "      model = BertForMaskedLM.from_pretrained('bert-base-multilingual-uncased')\n",
    "  else:\n",
    "    mask_token = '[MASK]'\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',output_hidden_states = do_PCA)\n",
    "    if do_PCA:\n",
    "      config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "      model = BertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "    else:\n",
    "      model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "  #show some tokens\n",
    "  #for i in np.round(np.random.rand(100)*2000):\n",
    "  #  print(tokenizer.convert_ids_to_tokens([i])[0])\n",
    "  return model, tokenizer, mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import unbalanced(unaugmented models)\n",
    "# def model_loader(which_bert = 'BERT', do_PCA = False):\n",
    "#   \"\"\"\n",
    "#   Loads model from BERT family.\n",
    "#   Input:\n",
    "#   which_bert: which bert to load\n",
    "#   do_PCA:     whether output of hidden layers is returned (required for doing embedding analysis)\n",
    "\n",
    "#   Returns model, tokenizer corresponding to input settings\n",
    "#   \"\"\"\n",
    "#   which_bert = which_bert.lower()\n",
    "#   if which_bert == 'roberta':\n",
    "#     mask_token = '<mask>'\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "# #       config = RobertaConfig.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "#       model = RobertaModel.from_pretrained(\"roberta-base\", config=config)  \n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/5_roberta_base_ontonotes_unbalanced.pth\")\n",
    "#   elif which_bert == 'distilbert':\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "# #       config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\", output_hidden_states=True)\n",
    "#       model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/7_distilbert_base_ontonotes_unbalanced.pth\")\n",
    "#   elif which_bert == 'bert-large':\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-large-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "# #       config = BertConfig.from_pretrained(\"bert-large-uncased\", output_hidden_states=True)\n",
    "#       model = BertModel.from_pretrained(\"bert-large-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/3_bert_large_ontonotes_unbalanced.pth\")\n",
    "#   elif which_bert == 'bert-base-multilingual':\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "#       config = BertConfig.from_pretrained(\"bert-base-multilingual-uncased\", output_hidden_states=True)\n",
    "# #       model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/9_multilingual_base_ontonotes_unbalanced.pth\")\n",
    "#   else:\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "#       config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "# #       model = BertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/1_bert_base_ontonotes_unbalanced.pth\")\n",
    "\n",
    "#   #show some tokens\n",
    "#   #for i in np.round(np.random.rand(100)*2000):\n",
    "#   #  print(tokenizer.convert_ids_to_tokens([i])[0])\n",
    "#   return model, tokenizer, mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import balanced(augmented models)\n",
    "# def model_loader(which_bert = 'BERT', do_PCA = False):\n",
    "#   \"\"\"\n",
    "#   Loads model from BERT family.\n",
    "#   Input:\n",
    "#   which_bert: which bert to load\n",
    "#   do_PCA:     whether output of hidden layers is returned (required for doing embedding analysis)\n",
    "\n",
    "#   Returns model, tokenizer corresponding to input settings\n",
    "#   \"\"\"\n",
    "#   which_bert = which_bert.lower()\n",
    "#   if which_bert == 'roberta':\n",
    "#     mask_token = '<mask>'\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "# #       config = RobertaConfig.from_pretrained(\"roberta-base\", output_hidden_states=True)\n",
    "#       model = RobertaModel.from_pretrained(\"roberta-base\", config=config)  \n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/5_roberta_base_ontonotes_balanced.pth\")\n",
    "#   elif which_bert == 'distilbert':\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "# #       config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\", output_hidden_states=True)\n",
    "#       model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/7_distilbert_base_ontonotes_balanced.pth\")\n",
    "#   elif which_bert == 'bert-large':\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-large-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "# #       config = BertConfig.from_pretrained(\"bert-large-uncased\", output_hidden_states=True)\n",
    "#       model = BertModel.from_pretrained(\"bert-large-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/3_bert_large_ontonotes_balanced.pth\")\n",
    "#   elif which_bert == 'bert-base-multilingual':\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "#       config = BertConfig.from_pretrained(\"bert-base-multilingual-uncased\", output_hidden_states=True)\n",
    "# #       model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/9_multilingual_base_ontonotes_balanced.pth\")\n",
    "#   else:\n",
    "#     mask_token = '[MASK]'\n",
    "#     tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',output_hidden_states = do_PCA)\n",
    "#     if do_PCA:\n",
    "#       config = BertConfig.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
    "# #       model = BertModel.from_pretrained(\"bert-base-uncased\", config=config)\n",
    "#     else:\n",
    "#       model = torch.load(\"ontonotes/1_bert_base_ontonotes_balanced.pth\")\n",
    "\n",
    "#   #show some tokens\n",
    "#   #for i in np.round(np.random.rand(100)*2000):\n",
    "#   #  print(tokenizer.convert_ids_to_tokens([i])[0])\n",
    "#   return model, tokenizer, mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NYxPaqh5eC9"
   },
   "outputs": [],
   "source": [
    "def generalise_profession_embeddings(string):\n",
    "  \"\"\"\n",
    "  Replace true profession in string with \"[profession]\".\n",
    "\n",
    "  :param str string: Input string from Winobias\n",
    "  :return generalised_string: string with \"[profession]\" \n",
    "    subbed in place of actuall profession\n",
    "  :return profession: entity profession \n",
    "  \"\"\"\n",
    "  regex_extracting_profession = r\"[\\s\\w]*(\\[[\\w\\s]*\\])[\\w\\s]*(\\[his\\]|\\[her\\]|\\[he\\]|\\[she\\]|)\"\n",
    "\n",
    "  # Extract profession/gender instances in string\n",
    "  profession, gender = re.findall(regex_extracting_profession, string)[0]\n",
    "  #print(profession, gender)\n",
    "  #print(\"Profession: {}, Gender: {}\".format(profession, gender)) # For debugging\n",
    "\n",
    "  # Remove brackets from\n",
    "  prof_amended = profession[1:-1]\n",
    "  # print(prof_amended)\n",
    "  \n",
    "  # Check if profession is multi-worded\n",
    "  prof_split = prof_amended.split()\n",
    "\n",
    "  if len(prof_split) > 1:\n",
    "    # If so, replace context with multiple 'profession' templates\n",
    "    prof_template = '[' + ' '.join(len(prof_split) * ['profession']) + ']'\n",
    "  else:\n",
    "    prof_template = \"[profession]\"\n",
    "\n",
    "  generalised_string = string.replace(profession, prof_template)\n",
    "\n",
    "  # Check if original profession is tokenised by > 1 token\n",
    "  gen_tokens = tokenizer.encode(generalised_string)\n",
    "  original_tokens = tokenizer.encode(string)\n",
    "\n",
    "  # If so count the number of \n",
    "  if len(original_tokens) > len(gen_tokens):\n",
    "    # Find number of elements in orig string not in gen string\n",
    "    diff_elems = set(original_tokens) - set(gen_tokens)\n",
    "    num_elems = len(diff_elems)\n",
    "    generalised_string = string.replace(\n",
    "      profession,\n",
    "      '[' + ' '.join(num_elems * ['mask']) + ']'\n",
    "    )\n",
    "  return generalised_string, profession\n",
    "\n",
    "\n",
    "def remove_the_from_brackets(string):\n",
    "  \"\"\"\n",
    "  Searches for whether there is a \"The\" in the profession-related\n",
    "  square brackets. If so, it extracts \"The\" and keeps only the professions\n",
    "  within the brackets.\n",
    "\n",
    "  e.g. \"[The engineer] was upset...\" => \"The [engineer] was upset...\"\n",
    "  :return str string: input string with \"The/the\" removed from the target entity\n",
    "  \"\"\"\n",
    "  # Idenitify whether the professional term starts with \"[The ...]\"\n",
    "  regex = \"[\\s\\w]*(\\[The [\\w\\s]*\\])[\\w\\s]*\"\n",
    "  profession_instance_The = re.findall(regex, string)\n",
    "  # If so, pull \"The\" outside of the square brackets\n",
    "  if len(profession_instance_The) > 0:\n",
    "    replacement = \"The [\" +  profession_instance_The[0][5:]\n",
    "    string = string.replace(profession_instance_The[0], replacement)\n",
    "\n",
    "  # Do the same for [the ...]\n",
    "  # Idenitify whether the professional term starts with \"[The ...]\"\n",
    "  regex = \"[\\s\\w]*(\\[the [\\w\\s]*\\])[\\w\\s]*\"\n",
    "  profession_instance_the = re.findall(regex, string)\n",
    "  # If so, pull \"The\" outside of the square brackets\n",
    "  if len(profession_instance_the) > 0:\n",
    "    replacement = \"the [\" +  profession_instance_the[0][5:]\n",
    "    string = string.replace(profession_instance_the[0], replacement)\n",
    "\n",
    "  return string\n",
    "\n",
    "\n",
    "def generalise_profession(string):\n",
    "  \"\"\"\n",
    "  Replace true profession in string with \"[profession]\".\n",
    "\n",
    "  :param str string: Input string from Winobias\n",
    "  :return generalised_string: string with \"[profession]\" \n",
    "    subbed in place of actuall profession\n",
    "  :return profession: entity profession \n",
    "\n",
    "  \"\"\"\n",
    "  regex_extracting_profession = r\"[\\s\\w]*(\\[[\\w\\s]*\\])[\\w\\s]*(\\[his\\]|\\[her\\]|\\[he\\]|\\[she\\]|)\"\n",
    "\n",
    "  # Extract profession/gender instances in string\n",
    "  profession, gender = re.findall(regex_extracting_profession, string)[0]\n",
    "  #print(profession, gender)\n",
    "  #print(\"Profession: {}, Gender: {}\".format(profession, gender)) # For debugging\n",
    "\n",
    "  # Test gender to check we have extracted the right quantities\n",
    "  assert gender in set([\"[his]\", \"[her]\", \"[he]\", \"[she]\", \"[him]\"]) # For debugging (always leave on)\n",
    "\n",
    "  # Remove brackets from\n",
    "  prof_amended = profession[1:-1]\n",
    "  # print(prof_amended)\n",
    "  \n",
    "  # Check if profession is multi-worded\n",
    "  prof_split = prof_amended.split()\n",
    "\n",
    "  if len(prof_split) > 1:\n",
    "    # If so, replace context with multiple 'profession' templates\n",
    "    prof_template = '[' + ' '.join(len(prof_split) * ['profession']) + ']'\n",
    "  else:\n",
    "    prof_template = \"[profession]\"\n",
    "\n",
    "  generalised_string = string.replace(profession, prof_template)\n",
    "\n",
    "  # Check if original profession is tokenised by > 1 token\n",
    "  gen_tokens = tokenizer.encode(generalised_string)\n",
    "  original_tokens = tokenizer.encode(string)\n",
    "\n",
    "  # If so count the number of \n",
    "  if len(original_tokens) > len(gen_tokens):\n",
    "    # Find number of elements in orig string not in gen string\n",
    "    diff_elems = set(original_tokens) - set(gen_tokens)\n",
    "    num_elems = len(diff_elems)\n",
    "    generalised_string = string.replace(\n",
    "      profession,\n",
    "      '[' + ' '.join(num_elems * ['profession']) + ']'\n",
    "    )\n",
    "  \n",
    "  return generalised_string, profession\n",
    "\n",
    "\n",
    "def identify_profession_token(string, general_string):\n",
    "  \"\"\"\n",
    "  Returns the index of the token corresponding to the string's profession\n",
    "  for a particular tokenizer.\n",
    "  \"\"\"\n",
    "  # print(string)\n",
    "  # Get tokens of the raw string and the generalised string\n",
    "  #return [len(string.split(']')[0])]\n",
    "  orig_tokens = np.array(tokenizer.encode(string))\n",
    "  gen_tokens = np.array(tokenizer.encode(general_string))\n",
    "\n",
    "  # By comparing the difference, identify which tokens correspond to the\n",
    "  # original profession\n",
    "  #print(orig_tokens, gen_tokens)\n",
    "  token_diff = orig_tokens - gen_tokens\n",
    "  non_zero_index = np.nonzero(token_diff)[0]\n",
    "  return non_zero_index.tolist()\n",
    "\n",
    "def change_gender(string, gender):\n",
    "  \"\"\"\n",
    "  Change string's pronoun to that corresponding to a user given gender\n",
    "  \"\"\"\n",
    "  term_a = r'(\\[his\\])|(\\[her\\])'\n",
    "  term_b = r'(\\[he\\])|(\\[she\\])'\n",
    "  term_c = r'(\\[him\\])|(\\[her\\])'\n",
    "  if gender == \"M\":\n",
    "    string = re.sub(term_a, '[his]', string)\n",
    "    string = re.sub(term_b, '[he]', string)\n",
    "    # string = re.sub(term_c, '[him]', string)\n",
    "    return string\n",
    "  elif gender == 'F':\n",
    "    string = re.sub(term_a, '[her]', string)\n",
    "    string = re.sub(term_b, '[she]', string)\n",
    "    string = re.sub(term_c, '[her]', string)\n",
    "\n",
    "    return string\n",
    "  else:\n",
    "      return ValueError(\"Need to specify appropirate gender: 'M' or 'F'\")\n",
    "\n",
    "\n",
    "def extract_professional_layer(string, ind, model, tokenizer):\n",
    "  \"\"\"\n",
    "  * Format string to remove brackets around gender/profession\n",
    "  * Tokenize/Encode and find embedding representation in BERT\n",
    "  \n",
    "  return: a tuple of embeddings indexed by layer number (i.e. layers[-1] will\n",
    "    be the final layer and layers[0] will be the first layer)\n",
    "\n",
    "  Method inspired from \n",
    "  https://github.com/huggingface/transformers/issues/1950\n",
    "  \"\"\"\n",
    "  regex_extracting_profession = r\"[\\s\\w]*(\\[\\w*\\])[\\w\\s]*(\\[his\\]|\\[her\\]|\\[he\\]|\\[she\\]|)\"\n",
    "  profession, gender = re.findall(regex_extracting_profession, string)[0]\n",
    "  \n",
    "  # Remove brackets around profession/gender\n",
    "  string = string.replace(profession, profession[1:-1])\n",
    "  string = string.replace(gender, gender[1:-1])\n",
    "  # print(\"Modified String {}\".format(string))\n",
    "  # print(string)\n",
    "  # print(type(string))\n",
    "\n",
    "  # Tokenize string and convert to torch.tensor\n",
    "  tokens = torch.tensor(tokenizer.encode(string)).unsqueeze(0)\n",
    "\n",
    "  # Extract embeddings by passing tokens into model and selecting 3rd return object\n",
    "  #print(tokens)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(tokens)\n",
    "    outputs = outputs[2]\n",
    "  assert tokens.shape[1] == outputs[0].shape[1] # Check each token has its own embedding\n",
    "\n",
    "  # Extract embedding from space and return as a tuple (ordered from first to last). \n",
    "  number_of_layers = len(outputs)\n",
    "  if len(ind) == 1:\n",
    "    layers = tuple(outputs[i][0][ind][0] for i in range(13))\n",
    "  # If multiple tokens for a mapping exist, take the mean\n",
    "  elif len(ind) > 1:\n",
    "    layers = tuple(outputs[i][0][ind][0].mean(1) for i in range(13))\n",
    "\n",
    "  return layers\n",
    "\n",
    "\n",
    "def extract_gendered_profession_emb(string, model, tokenizer):\n",
    "  \"\"\"\n",
    "  Create template string replacing profession with a template value\n",
    "   \n",
    "  * extract profession from text\n",
    "  * duplicate it ans sub with \"profession\" term\n",
    "  * tokenise and identify which layer will relate to contextualised layer for that profession\n",
    "\n",
    "  Returns embedding representation for a profession within a string for\n",
    "    male and female pronouns. The index corresponding to the professional\n",
    "    token, and the profession string itself, are also returned\n",
    "\n",
    "  \"\"\"\n",
    "  string = remove_the_from_brackets(string)\n",
    "  # print(string) # for debugging\n",
    "  general_string, profession = generalise_profession(string)\n",
    "  token_index = identify_profession_token(string, general_string)\n",
    "  #if len(token_index) > 1: # Warns when more than one token is used for a profession\n",
    "  #  print(\"\"\"\n",
    "  #    WARNING: profession for {} is represented with more than one token ({})\n",
    "  #  \"\"\".format(string, token_index))\n",
    "  male_string = change_gender(string, gender='M')\n",
    "  female_string = change_gender(string, gender='F')\n",
    "  male_representation = extract_professional_layer(\n",
    "    male_string, token_index, model, tokenizer\n",
    "  )\n",
    "  female_representation = extract_professional_layer(\n",
    "    female_string, token_index, model, tokenizer\n",
    "  )\n",
    "  return male_representation, female_representation, token_index, profession\n",
    "\n",
    "\n",
    "def extract_full_layer(string, ind, model, tokenizer):\n",
    "  \"\"\"\n",
    "  * Format string to remove brackets around gender/profession\n",
    "  * Tokenize/Encode and find embedding representation in BERT\n",
    "  \n",
    "  return: a tuple of embeddings indexed by layer number (i.e. layers[-1] will\n",
    "    be the final layer and layers[0] will be the first layer)\n",
    "\n",
    "  Method inspired from \n",
    "  https://github.com/huggingface/transformers/issues/1950\n",
    "  \"\"\"\n",
    "  regex_extracting_profession = r\"[\\s\\w]*(\\[\\w*\\])[\\w\\s]*(\\[his\\]|\\[her\\]|\\[he\\]|\\[she\\]|)\"\n",
    "  profession, gender = re.findall(regex_extracting_profession, string)[0]\n",
    "  \n",
    "  # Remove brackets around profession/gender\n",
    "  string = string.replace(profession, profession[1:-1])\n",
    "  string = string.replace(gender, gender[1:-1])\n",
    "  # print(\"Modified String {}\".format(string))\n",
    "  # print(string)\n",
    "  # print(type(string))\n",
    "\n",
    "  # Tokenize string and convert to torch.tensor\n",
    "  tokens = torch.tensor(tokenizer.encode(string)).unsqueeze(0)\n",
    "\n",
    "  # Extract embeddings by passing tokens into model and selecting 3rd return object\n",
    "  #print(tokens)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(tokens)\n",
    "    outputs = outputs[2]\n",
    "  assert tokens.shape[1] == outputs[0].shape[1] # Check each token has its own embedding\n",
    "\n",
    "  # Extract embedding from space and return as a tuple (ordered from first to last). \n",
    "  number_of_layers = len(outputs)\n",
    "  if len(ind) == 1:\n",
    "    layers = tuple(outputs[i][0][:][0] for i in range(13))\n",
    "  # If multiple tokens for a mapping exist, take the mean\n",
    "  elif len(ind) > 1:\n",
    "    layers = tuple(outputs[i][0][:][0].mean(1) for i in range(13))\n",
    "\n",
    "  return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Or6Y4xUGSr41"
   },
   "source": [
    "Load which professions are stereotypically male/female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8QLyXpXbXAL"
   },
   "outputs": [],
   "source": [
    "def get_gendered_profs():\n",
    "  \"\"\"\n",
    "  Returns lists of stereotypically male and female professions [US Labor Statistics 2017]\n",
    "  \"\"\"\n",
    "  # Labor statistics from US 2017 population survey\n",
    "  dic_of_profs = {'carpenter': 2,'mechanic':4,'construction worker':4, 'laborer':4, 'driver':6,'sheriff':14,'mover':18, 'developer':20, 'farmer':22,'guard':22,\n",
    "              'chief':27,'janitor':34,'lawyer':35,'cook':38,'physician':38,'CEO':39, 'analyst':41,'manager':43, 'supervisor':44, 'salesperson':48, 'editor':52, 'designer':54,'accountant':61,'auditor':61, 'writer':63,'baker':65,'clerk':72,\n",
    "              'cashier':73, 'counselor':73, 'attendant':76, 'teacher':78, 'sewer':80, 'librarian':84, 'assistant':85, 'cleaner':89, 'housekeeper':89,'nurse':90,'receptionist':90, 'hairdresser':92, 'secretary':95}\n",
    "  mprofs = []\n",
    "  fprofs = []\n",
    "  for key in dic_of_profs.keys():\n",
    "    if dic_of_profs[key] >50:\n",
    "      fprofs.append(key)\n",
    "    else:\n",
    "      mprofs.append(key)\n",
    "\n",
    "  # WinoBias includes profession \"tailor\" that is stereotypically male [Zhao et al 2019]\n",
    "  mprofs.append('tailor')\n",
    "\n",
    "  return mprofs,fprofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuaDn2NuSxvz"
   },
   "source": [
    "Simple sentiment analysis for checking whether classification depends on sentiment (result: no indication of any correlation between sentiment and predictive power or gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "H2_1SoIQvJPr",
    "outputId": "c06566a6-8e0a-4b73-d1f5-a0e6ddfdeb93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment test of negative sentence: -0.8445\n",
      "Sentiment test of positive sentence: 0.8578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/etokpoua/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "  \n",
    "def get_vader_score(sent):\n",
    "  \"\"\"\n",
    "  Simple sentiment analyser used to check whether classification depends on sentiment\n",
    "  \"\"\"\n",
    "  # Polarity score returns dictionary\n",
    "  ss = sid.polarity_scores(sent)\n",
    "  return ss[sorted(ss)[0]]\n",
    "\n",
    "def sentiment_tester(df):\n",
    "  \"\"\"\n",
    "  Input:\n",
    "  df_pred    pandas dataframe with results from function predict\n",
    "  \"\"\"\n",
    "  print('mean sentiment of stereotypical sentences:\\n',np.mean(df_pred['Sentiment']))\n",
    "\n",
    "  print('mean sentiment of stereotypical sentences with female label:\\n',np.mean(df_pred['Sentiment'][np.logical_or( ['True Label'] == 'she',df_pred['True Label'] == 'her')]))\n",
    "  print('mean sentiment of stereotypical sentences with male label:\\n',np.mean(df_pred['Sentiment'][~np.logical_or(df_pred['True Label'] == 'she',df_pred['True Label'] == 'her')]))\n",
    "  print('mean sentiment of sentences that are classified as female:\\n',np.mean(df_pred['Sentiment'][df_pred['Female Probability']>df_pred['Male Probability']]))\n",
    "  print('mean sentiment of sentences that are classified as male:\\n',np.mean(df_pred['Sentiment'][df_pred['Female Probability']<df_pred['Male Probability']]))\n",
    "\n",
    "print('Sentiment test of negative sentence:', get_vader_score(\"This is a really negative sentence, it's absolutely horrific\"))\n",
    "print('Sentiment test of positive sentence:', get_vader_score(\"This is a really positive sentence that is making me incredibly happy\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SU-kJfOpVP75"
   },
   "source": [
    "## Data formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZeE3-l-eHB-"
   },
   "outputs": [],
   "source": [
    "def data_formatter(filename, embed_data = False, mask_token = '[MASK]', model = None, tokenizer = None, baseline_tester= False, reverse = True, female_name = 'Alice', male_name = 'Bob'):\n",
    "  \"\"\"\n",
    "  Formats data by masking pronoun and masked sentences in new file\n",
    "  filename      - input WinoBias file\n",
    "  embed_data    - if False:  Returns pro- and anti-stereotypical pronouns, the profession the pronoun refers to and the sentiment of sentences\n",
    "                  if True: this function returns the final BERT embeddings of the profession token (needed for PCA)\n",
    "  baseline_tester - 0 use WinoBias set\n",
    "                  1 replace both professions by stereotypical names (used for testing baseline coreference performance)\n",
    "                  2 replace referenced profession by stereotypical name\n",
    "  reverse       - if baseline_tester is on, include sentences where names and pronouns are swapped \n",
    "                  e.g. for \"Alice sees Bob and [she] asks...\", also include \"Bob sees Alice and [he] asks ... \". Decreases variance.\n",
    "  mask_token    - mask token used by BERT model (either [MASK]  or <mask>)\n",
    "  model         - specific BERT model\n",
    "  tokenizer     - tokenizer used by BERT model\n",
    "  \"\"\"\n",
    "  # Initialise\n",
    "  masklabels = []\n",
    "  professions = []\n",
    "  sentiments = []\n",
    "\n",
    "  # Experimenting with masking the he/she/his/her\n",
    "  f = open(eval('pro'+filename), \"r\") \n",
    "  lines = f.readlines()\n",
    "  f.close()\n",
    "  f = open(eval('anti'+filename), \"r\") \n",
    "  lines_anti = f.readlines()\n",
    "  f.close()\n",
    "  if baseline_tester: mprofs, fprofs = get_gendered_profs()\n",
    "\n",
    "  textfile = open(filename+'.txt', 'w')\n",
    "  embedded_data = []\n",
    "  for i,line in enumerate(lines):\n",
    "\n",
    "    #chech if one of the words in the sentence is he/she/his/her\n",
    "    mask_regex = r\"(\\[he\\]|\\[she\\]|\\[him\\]|\\[his\\]|\\[her\\]|\\[He\\]|\\[She\\]|\\[His\\]|\\[Her\\])\"\n",
    "    pronoun = re.findall(mask_regex, line)\n",
    "    if len(pronoun) == 1: ######## Dan/Dave what's the idea of this again?\n",
    "      pronoun = pronoun[0][1:-1]\n",
    "      pronoun_anti = re.findall(mask_regex, lines_anti[i])[0][1:-1]\n",
    "      \n",
    "      # Remove number at start of line\n",
    "      new_line = re.sub(r\"^(\\d*)\", \"\", line)\n",
    "      new_line = re.sub(r\"(.)$\", \" . \", new_line[1:])\n",
    "      \n",
    "      \n",
    "      profession_pre = re.findall('\\[(.*?)\\]',new_line)[0]\n",
    "      if profession_pre[1:4] == 'he ': \n",
    "        profession = profession_pre[4:] # i.e. the/The\n",
    "      elif profession_pre[0:2] =='a ':\n",
    "        profession = profession_pre[2:]\n",
    "      else:\n",
    "        profession = profession_pre\n",
    "      professions.append(profession)\n",
    "\n",
    "      if embed_data:\n",
    "        try:\n",
    "          male_representation, female_representation, token_index, profession = extract_gendered_profession_emb(new_line, model, tokenizer)\n",
    "      # removes all square brackets\n",
    "        except:\n",
    "          continue\n",
    "      new_line = re.sub(mask_regex, mask_token, new_line)\n",
    "      \n",
    "      \n",
    "      new_line = re.sub(r'\\[(.*?)\\]',lambda L: L.group(1).rsplit('|', 1)[-1], new_line)\n",
    "      \n",
    "      # replace square brackets on MASK\n",
    "      new_line = re.sub('MASK', '[MASK]', new_line)\n",
    "      \n",
    "      # Sentiment analysis of sentences\n",
    "      sentiments.append([get_vader_score(line),get_vader_score(lines_anti[i]),get_vader_score(new_line)])\n",
    "      \n",
    "      if reverse:\n",
    "        new_line_rev = copy(new_line)\n",
    "\n",
    "      if baseline_tester:\n",
    "        if pronoun in ('she', 'her'):\n",
    "          new_line = new_line.replace(profession_pre, female_name)\n",
    "          \n",
    "        else:\n",
    "          new_line = new_line.replace(profession_pre, male_name)\n",
    "        if baseline_tester==1:\n",
    "          for prof in mprofs:\n",
    "            new_line = new_line.replace('The '+prof, male_name)\n",
    "            new_line = new_line.replace('the '+prof, male_name)\n",
    "            new_line = new_line.replace('a '+prof, male_name)\n",
    "            new_line = new_line.replace('A '+prof, male_name)\n",
    "            \n",
    "          for prof in fprofs:\n",
    "            new_line = new_line.replace('The '+prof, female_name)\n",
    "            new_line = new_line.replace('the '+prof, female_name)\n",
    "            new_line = new_line.replace('a '+prof, female_name)\n",
    "            new_line = new_line.replace('A '+prof, female_name)\n",
    "\n",
    "      new_line = new_line.lstrip().rstrip()\n",
    "      textfile.write(new_line+ '\\n')\n",
    "      masklabels.append([pronoun,pronoun_anti])\n",
    "\n",
    "      if reverse and baseline_tester:\n",
    "        if pronoun in ('she', 'her'):\n",
    "          new_line_rev = new_line_rev.replace(profession_pre, male_name)\n",
    "          \n",
    "        else:\n",
    "          new_line_rev = new_line_rev.replace(profession_pre, female_name)\n",
    "        if baseline_tester==2:\n",
    "          for prof in fprofs:\n",
    "            new_line_rev = new_line_rev.replace('The '+prof, male_name)\n",
    "            new_line_rev = new_line_rev.replace('the '+prof, male_name)\n",
    "            new_line_rev = new_line_rev.replace('a '+prof, male_name)\n",
    "            new_line_rev = new_line_rev.replace('A '+prof, male_name)\n",
    "          for prof in mprofs:\n",
    "            new_line_rev = new_line_rev.replace('The '+prof, female_name)\n",
    "            new_line_rev = new_line_rev.replace('the '+prof, female_name)\n",
    "            new_line_rev = new_line_rev.replace('a '+prof, female_name)\n",
    "            new_line_rev = new_line_rev.replace('A '+prof, female_name)\n",
    "\n",
    "        textfile.write(new_line_rev)\n",
    "        masklabels.append([pronoun_anti,pronoun])\n",
    "        professions.append('removed prof')\n",
    "        sentiments.append([-100,-100,-100])\n",
    "        \n",
    "      if embed_data:\n",
    "        stereotypical_gender = pronoun.lower() not in ('she', 'her')\n",
    "        embedded_data.append([i, male_representation, female_representation, stereotypical_gender, profession, token_index])\n",
    "\n",
    "      # write this line to new \"masked\" text file\n",
    "      \n",
    "      # print(line)\n",
    "      # get the label without square brackets\n",
    "      # print(new_m)\n",
    "    else:\n",
    "      pass\n",
    "\n",
    "  #print(maskprodev1labels)\n",
    "  textfile.close()\n",
    "  # check it worked\n",
    "  #f = open(\"maskprodev1.txt\", \"r\") \n",
    "  #print(f.read())\n",
    "  f.close()\n",
    "\n",
    "  if embed_data:\n",
    "    return embedded_data\n",
    "  else:\n",
    "    return masklabels, professions, np.array(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tjnmg-90G-mj"
   },
   "source": [
    "## Predictions (No fine tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qx6__jGxUhIg"
   },
   "source": [
    "We will now loop through the dataset and do the following:\n",
    "\n",
    "* identify the label for this example so we know whether we are comparing [he] vs [she] scores or [him] vs [her] scores\n",
    "\n",
    "* get BERT to predict the [MASK] and then extract the scores for each of the two possible answers\n",
    "\n",
    "* record whether the classification is pro- or anti-stereotypical\n",
    "\n",
    "At the end we can get accuracy and F1 (wrt pro- and anti-stereotypical labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tp-qLhqWvwg"
   },
   "outputs": [],
   "source": [
    "def predict(dataset, labels, professions, model, tokenizer, mask_token, use_elmo = 0, verbose= False, online_skew_mit = 0):\n",
    "  \"\"\"\n",
    "  Input:\n",
    "  dataset             - dataset name (reads from .txt)\n",
    "  labels              - possible pronouns (every entry contains stereotypical and anti-stereotypical option)\n",
    "  professions         - professions that the pronoun references to\n",
    "  use_elmo            - boolean that denotes to use ELMo or not\n",
    "  verbose             - print wrong predictions\n",
    "  online_skew_mit - 0 use BERT output pronoun ({him, his, he} vs {she, her} probabilities\n",
    "                        1 divide default output by pronoun probabilities of sentences in which all professions are masked\n",
    "                        2 divide default output by gender probabilities in which just the referenced profession is masked\n",
    "  Output:\n",
    "  df_output           - pandas dataframe with predictions, pro and anti-stereo pronouns, professions, probabilities for either gendered pronouns\n",
    "  n_misk              - list with number of classifications for each gender\n",
    "  n_misk_profs        - dictionary with number of classifications for each gender for each profession\n",
    "  \"\"\"\n",
    "  \n",
    "  predicted_output = []\n",
    "\n",
    "  # read text file\n",
    "  f = open(dataset+'.txt', \"r\") \n",
    "  lines = f.readlines()\n",
    "  f.close()\n",
    "  n_misk = [0,0]\n",
    "  n_misk_prof = {}\n",
    "  if use_elmo: embedder_ELMo = load_elmo()\n",
    "\n",
    "  for prof in set(professions):\n",
    "    n_misk_prof[prof] = [0,0] # mistakes per profession\n",
    "  # loop over lines\n",
    "  print('Running on', len(lines), 'examples')\n",
    "  mprofs,fprofs = get_gendered_profs()\n",
    "  for idx,line in enumerate(lines):\n",
    "    \n",
    "    line_output = []\n",
    "    # read the line and its label\n",
    "    line = lines[idx]\n",
    "    label = labels[idx][0]\n",
    "    label_anti = labels[idx][1]\n",
    "    \n",
    "    # identify relevant tokens to compare\n",
    "    \n",
    "    if label.lower() not in ('she','her'):\n",
    "      male_label = label\n",
    "      female_label = label_anti\n",
    "      g_index = 1\n",
    "    else:\n",
    "      male_label = label_anti\n",
    "      female_label = label\n",
    "      g_index = 0\n",
    "    \n",
    "    comparison_labels = [male_label,female_label]\n",
    "    #comparison_labels = [label,label_anti]\n",
    "    \n",
    "    comparison_indices = tokenizer.convert_tokens_to_ids(comparison_labels)\n",
    "    \n",
    "      \n",
    "    # tokenise the line\n",
    "    if use_elmo==0:\n",
    "      input_ids = torch.tensor(tokenizer.encode(line)).unsqueeze(0)  # Batch size 1\n",
    "      masked_index = (input_ids == tokenizer.convert_tokens_to_ids([mask_token])[0]).nonzero()\n",
    "      \n",
    "      \n",
    "      masked_index = masked_index[0,-1]\n",
    "      if online_skew_mit:\n",
    "        new_line = line\n",
    "        if online_skew_mit==1:\n",
    "          for prof in mprofs+fprofs+[female_name, male_name]:\n",
    "            new_line = new_line.replace(prof, mask_token)#+str(int(round(random.random()*100)))+']')\n",
    "        else:\n",
    "          new_line = new_line.replace(professions[idx], mask_token )\n",
    "        input_ids_2 = torch.tensor(tokenizer.encode(new_line)).unsqueeze(0)  # Batch size 1\n",
    "        masked_index_2 = (input_ids_2 == tokenizer.convert_tokens_to_ids([mask_token])[0]).nonzero()\n",
    "        \n",
    "        masked_index_2 = masked_index_2[0,-1] # choose last mask token in sentence, that corresponds to he she\n",
    "        \n",
    "      \n",
    "      #print(tokenizer.convert_ids_to_tokens(input_ids.squeeze()), masked_index, line) #for debuggig\n",
    "\n",
    "      with torch.no_grad(): #necessary?\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        \n",
    "        # print(tokenizer.convert_ids_to_tokens(input_ids[:,masked_index])) # for debugging: Check that masked index is indeed correctly defined\n",
    "        prediction_scores = outputs[1]\n",
    "        scores = prediction_scores[0, masked_index]\n",
    "        probs = torch.nn.functional.softmax(scores)\n",
    "        predicted_index = torch.argmax(scores)\n",
    "        if online_skew_mit:\n",
    "          outputs_2 = model(input_ids_2, labels=input_ids_2)\n",
    "          prediction_scores_2 = outputs_2[1]\n",
    "          scores_2 = prediction_scores_2[0, masked_index_2]\n",
    "          probs_2 = torch.nn.functional.softmax(scores_2)\n",
    "          \n",
    "      \n",
    "      predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "      if online_skew_mit:\n",
    "#         prob_normalisation\n",
    "        male_prob = probs[comparison_indices[0]]/probs_2[comparison_indices[0]]\n",
    "        female_prob = probs[comparison_indices[1]]/probs_2[comparison_indices[1]]\n",
    "      else:\n",
    "        male_prob = probs[comparison_indices[0]]\n",
    "        female_prob = probs[comparison_indices[1]]\n",
    "\n",
    "    elif use_elmo == 1:\n",
    "      male_prob, female_prob = ELMoprobs(line, male_label, female_label, embedder_ELMo)\n",
    "      predicted_token = None\n",
    "      \n",
    "    else: ### deprecated method of using BERT embedding distance for classification\n",
    "      male_prob, female_prob = BERTembeddingdistances(line, male_label, female_label, model, tokenizer)\n",
    "    #if which_bert == 'Roberta' or which_bert == 'Albert':\n",
    "    #  predicted_token = predicted_token[:]\n",
    "    male_prob = float(male_prob)\n",
    "    female_prob = float(female_prob)\n",
    "    # Append results to list\n",
    "    line_output.append(idx)\n",
    "    line_output.append(predicted_token)\n",
    "    line_output.append(float(male_prob))\n",
    "    line_output.append(float(female_prob))\n",
    "    line_output.append(label)\n",
    "    line_output.append(label_anti)\n",
    "    line_output.append(professions[idx])\n",
    "    #line_output.append(predicted_token==label)\n",
    "    \n",
    "    predicted_output.append(line_output)\n",
    "    \n",
    "    \n",
    "    predicted_token = [male_label, female_label][male_prob<female_prob]\n",
    "    mistake_made = g_index != bool((float(male_prob)>float(female_prob))) \n",
    "    \n",
    "    n_misk[male_prob<female_prob]+=1\n",
    "\n",
    "    n_misk_prof[professions[idx]][male_prob<female_prob]+=1\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "      if mistake_made:  \n",
    "        print(\"\\n\\n---------- RESULT {} ---------- \\n Original Sentence = {} \\n Top [MASK] Prediction = {} \\n Male Probability = {} \\n Female Probability = {}\\n Sentiment of masked sentence = {}\".format(idx+1,line,predicted_token, line_output[2], line_output[3],sentiments[idx,2]))\n",
    "        print('Possible labels:', male_label, female_label)\n",
    "  \n",
    "  df_output = pd.DataFrame(predicted_output, columns = ['line', 'Top [MASK] Prediction', 'Male Probability', 'Female Probability', 'True Label', 'Anti Label', 'Profession'])\n",
    "  \n",
    "  return df_output, n_misk, n_misk_prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTCxsnYabLVD"
   },
   "source": [
    "# Testing (every model except for fine-tuned ones)\n",
    "For testing we loop over BERT, RoBERTa and DistilBERT, loop over WinoBias test sets 1 and 2 [Zhao et al 2018] and find the F1 scores on the pro vs anti-stereotypical data set, for both male and female. Additionally, for every model we include results when we the Online Skewness Mitigation method (see Section 4 of report)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SkGHSokRYyJe",
    "outputId": "700c6b5c-29ef-4d0f-d3b1-838f9cf5857c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%% BERT %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of male vs female predictions 70 : 304\n",
      "accuracy_pro =  51.06951871657755\n",
      "accuracy_ant =  48.93048128342246\n",
      "Delta acc = 2.1390374331550888\n",
      "f1 pro M = 62.576687116564415\n",
      "f1 ant M = 61.257606490872206\n",
      "Delta M = 1.3190806256922087\n",
      "f1 pro F = 29.343629343629342\n",
      "f1 ant F = 25.09803921568628\n",
      "Delta F = 4.245590127943061\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.0\n",
      "sheriff 0.16666666666666666\n",
      "receptionist 0.9090909090909091\n",
      "nurse 1.0\n",
      "cook 0.46153846153846156\n",
      "farmer 0.125\n",
      "janitor 0.25\n",
      "cashier 0.0\n",
      "mechanic 0.125\n",
      "construction worker 0.16666666666666666\n",
      "tailor 0.0\n",
      "secretary 0.2857142857142857\n",
      "developer 0.125\n",
      "manager 0.2857142857142857\n",
      "accountant 0.0\n",
      "salesperson 0.2222222222222222\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.3333333333333333\n",
      "cleaner 0.09090909090909091\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.125\n",
      "clerk 0.0\n",
      "lawyer 0.14285714285714285\n",
      "attendant 0.14285714285714285\n",
      "physician 0.2222222222222222\n",
      "designer 0.0\n",
      "carpenter 0.07692307692307693\n",
      "hairdresser 0.125\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.1111111111111111\n",
      "counselor 0.21428571428571427\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.4\n",
      "laborer 0.0\n",
      "housekeeper 0.9\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 61 : 330\n",
      "accuracy_pro =  54.987212276214834\n",
      "accuracy_ant =  45.012787723785166\n",
      "Delta acc = 9.974424552429667\n",
      "f1 pro M = 66.41221374045801\n",
      "f1 ant M = 58.89101338432122\n",
      "Delta M = 7.521200356136795\n",
      "f1 pro F = 31.782945736434105\n",
      "f1 ant F = 16.988416988416986\n",
      "Delta F = 14.794528748017118\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.125\n",
      "sheriff 0.0\n",
      "receptionist 1.0\n",
      "nurse 1.0\n",
      "cook 0.46153846153846156\n",
      "farmer 0.0\n",
      "janitor 0.15384615384615385\n",
      "cashier 0.0\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.0\n",
      "secretary 0.25\n",
      "developer 0.125\n",
      "manager 0.16666666666666666\n",
      "accountant 0.0\n",
      "salesperson 0.3\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.2\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.14285714285714285\n",
      "physician 0.1111111111111111\n",
      "designer 0.125\n",
      "carpenter 0.0\n",
      "hairdresser 0.25\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.0\n",
      "counselor 0.2857142857142857\n",
      "guard 0.1\n",
      "editor 0.0\n",
      "supervisor 0.2\n",
      "laborer 0.0\n",
      "housekeeper 0.9\n",
      "%%%%%%%%%%%%%%%%%%%%%%% BERT-O %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of male vs female predictions 74 : 300\n",
      "accuracy_pro =  53.20855614973262\n",
      "accuracy_ant =  46.79144385026738\n",
      "Delta acc = 6.417112299465245\n",
      "f1 pro M = 63.917525773195884\n",
      "f1 ant M = 59.30470347648262\n",
      "Delta M = 4.6128222967132615\n",
      "f1 pro F = 33.460076045627375\n",
      "f1 ant F = 23.166023166023173\n",
      "Delta F = 10.294052879604202\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.0\n",
      "sheriff 0.16666666666666666\n",
      "receptionist 0.9090909090909091\n",
      "nurse 1.0\n",
      "cook 0.3076923076923077\n",
      "farmer 0.0\n",
      "janitor 0.25\n",
      "cashier 0.0\n",
      "mechanic 0.125\n",
      "construction worker 0.16666666666666666\n",
      "tailor 0.0\n",
      "secretary 0.42857142857142855\n",
      "developer 0.125\n",
      "manager 0.2857142857142857\n",
      "accountant 0.0\n",
      "salesperson 0.3333333333333333\n",
      "driver 0.1111111111111111\n",
      "baker 0.0\n",
      "analyst 0.1111111111111111\n",
      "cleaner 0.09090909090909091\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.25\n",
      "clerk 0.0\n",
      "lawyer 0.21428571428571427\n",
      "attendant 0.0\n",
      "physician 0.1111111111111111\n",
      "designer 0.14285714285714285\n",
      "carpenter 0.07692307692307693\n",
      "hairdresser 0.25\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.1111111111111111\n",
      "counselor 0.42857142857142855\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.5\n",
      "laborer 0.0\n",
      "housekeeper 1.0\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 54 : 337\n",
      "accuracy_pro =  56.77749360613811\n",
      "accuracy_ant =  43.22250639386189\n",
      "Delta acc = 13.554987212276217\n",
      "f1 pro M = 68.17325800376648\n",
      "f1 ant M = 58.11320754716981\n",
      "Delta M = 10.06005045659667\n",
      "f1 pro F = 32.669322709163346\n",
      "f1 ant F = 11.904761904761907\n",
      "Delta F = 20.76456080440144\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.1\n",
      "librarian 0.0\n",
      "sheriff 0.07692307692307693\n",
      "receptionist 0.9090909090909091\n",
      "nurse 1.0\n",
      "cook 0.23076923076923078\n",
      "farmer 0.0\n",
      "janitor 0.07692307692307693\n",
      "cashier 0.0\n",
      "mechanic 0.1\n",
      "construction worker 0.0\n",
      "tailor 0.0\n",
      "secretary 0.25\n",
      "developer 0.125\n",
      "manager 0.16666666666666666\n",
      "accountant 0.0\n",
      "salesperson 0.0\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.07142857142857142\n",
      "attendant 0.14285714285714285\n",
      "physician 0.2222222222222222\n",
      "designer 0.25\n",
      "carpenter 0.0\n",
      "hairdresser 0.25\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.0\n",
      "counselor 0.2857142857142857\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.1\n",
      "laborer 0.0\n",
      "housekeeper 0.9\n",
      "%%%%%%%%%%%%%%%%%%%%%%% RoBERTa %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 98 : 276\n",
      "accuracy_pro =  57.48663101604278\n",
      "accuracy_ant =  42.513368983957214\n",
      "Delta acc = 14.973262032085564\n",
      "f1 pro M = 65.50976138828632\n",
      "f1 ant M = 53.76344086021505\n",
      "Delta M = 11.746320528071273\n",
      "f1 pro F = 44.599303135888505\n",
      "f1 ant F = 24.028268551236746\n",
      "Delta F = 20.57103458465176\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.2\n",
      "librarian 0.42857142857142855\n",
      "sheriff 0.0\n",
      "receptionist 0.7272727272727273\n",
      "nurse 0.75\n",
      "cook 0.23076923076923078\n",
      "farmer 0.25\n",
      "janitor 0.3333333333333333\n",
      "cashier 0.5\n",
      "mechanic 0.0\n",
      "construction worker 0.16666666666666666\n",
      "tailor 0.0\n",
      "secretary 0.7142857142857143\n",
      "developer 0.125\n",
      "manager 0.42857142857142855\n",
      "accountant 0.0\n",
      "salesperson 0.3333333333333333\n",
      "driver 0.1111111111111111\n",
      "baker 0.2\n",
      "analyst 0.1111111111111111\n",
      "cleaner 0.18181818181818182\n",
      "auditor 0.14285714285714285\n",
      "CEO 0.2\n",
      "assistant 0.25\n",
      "clerk 0.42857142857142855\n",
      "lawyer 0.0\n",
      "attendant 0.21428571428571427\n",
      "physician 0.3333333333333333\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.875\n",
      "chief 0.3\n",
      "mover 0.0\n",
      "writer 0.1111111111111111\n",
      "counselor 0.35714285714285715\n",
      "guard 0.1\n",
      "editor 0.16666666666666666\n",
      "supervisor 0.5\n",
      "laborer 0.4\n",
      "housekeeper 0.8\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 229 : 162\n",
      "accuracy_pro =  66.24040920716112\n",
      "accuracy_ant =  33.75959079283887\n",
      "Delta acc = 32.48081841432225\n",
      "f1 pro M = 62.92134831460674\n",
      "f1 ant M = 27.042253521126757\n",
      "Delta M = 35.87909479347998\n",
      "f1 pro F = 69.01408450704226\n",
      "f1 ant F = 39.344262295081975\n",
      "Delta F = 29.66982221196028\n",
      "Female ratio of assignments per profession\n",
      "teacher 1.0\n",
      "librarian 0.625\n",
      "sheriff 0.38461538461538464\n",
      "receptionist 1.0\n",
      "nurse 1.0\n",
      "cook 0.6153846153846154\n",
      "farmer 0.5\n",
      "janitor 0.15384615384615385\n",
      "cashier 0.75\n",
      "mechanic 0.3\n",
      "construction worker 0.2857142857142857\n",
      "tailor 0.25\n",
      "secretary 1.0\n",
      "developer 0.5\n",
      "manager 0.6666666666666666\n",
      "accountant 0.5\n",
      "salesperson 0.9\n",
      "driver 0.18181818181818182\n",
      "baker 0.5\n",
      "analyst 0.6\n",
      "cleaner 0.7272727272727273\n",
      "auditor 0.8571428571428571\n",
      "CEO 0.4\n",
      "assistant 0.75\n",
      "clerk 1.0\n",
      "lawyer 0.42857142857142855\n",
      "attendant 0.8571428571428571\n",
      "physician 0.5555555555555556\n",
      "designer 0.375\n",
      "carpenter 0.0\n",
      "hairdresser 0.875\n",
      "chief 0.4\n",
      "mover 0.2\n",
      "writer 0.8\n",
      "counselor 0.7142857142857143\n",
      "guard 0.6\n",
      "editor 0.6666666666666666\n",
      "supervisor 0.7\n",
      "laborer 0.16666666666666666\n",
      "housekeeper 1.0\n",
      "%%%%%%%%%%%%%%%%%%%%%%% RoBERTa-O %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 222 : 152\n",
      "accuracy_pro =  54.81283422459893\n",
      "accuracy_ant =  45.18716577540107\n",
      "Delta acc = 9.62566844919786\n",
      "f1 pro M = 49.85163204747775\n",
      "f1 ant M = 39.882697947214076\n",
      "Delta M = 9.968934100263674\n",
      "f1 pro F = 58.88077858880778\n",
      "f1 ant F = 49.631449631449634\n",
      "Delta F = 9.249328957358145\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.4\n",
      "librarian 0.5714285714285714\n",
      "sheriff 0.3333333333333333\n",
      "receptionist 0.9090909090909091\n",
      "nurse 0.875\n",
      "cook 0.7692307692307693\n",
      "farmer 0.625\n",
      "janitor 0.4166666666666667\n",
      "cashier 0.5\n",
      "mechanic 0.5\n",
      "construction worker 0.5\n",
      "tailor 0.15384615384615385\n",
      "secretary 0.8571428571428571\n",
      "developer 0.625\n",
      "manager 0.8571428571428571\n",
      "accountant 0.375\n",
      "salesperson 0.8888888888888888\n",
      "driver 0.4444444444444444\n",
      "baker 0.4\n",
      "analyst 0.7777777777777778\n",
      "cleaner 0.2727272727272727\n",
      "auditor 0.5714285714285714\n",
      "CEO 0.8\n",
      "assistant 0.75\n",
      "clerk 0.8571428571428571\n",
      "lawyer 0.5\n",
      "attendant 0.7142857142857143\n",
      "physician 0.4444444444444444\n",
      "designer 0.5714285714285714\n",
      "carpenter 0.15384615384615385\n",
      "hairdresser 1.0\n",
      "chief 0.2\n",
      "mover 0.75\n",
      "writer 0.8888888888888888\n",
      "counselor 0.5714285714285714\n",
      "guard 0.4\n",
      "editor 0.8333333333333334\n",
      "supervisor 0.9\n",
      "laborer 0.4\n",
      "housekeeper 1.0\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 43 : 348\n",
      "accuracy_pro =  54.987212276214834\n",
      "accuracy_ant =  45.012787723785166\n",
      "Delta acc = 9.974424552429667\n",
      "f1 pro M = 67.52767527675276\n",
      "f1 ant M = 60.258780036968574\n",
      "Delta M = 7.268895239784186\n",
      "f1 pro F = 26.666666666666668\n",
      "f1 ant F = 10.788381742738588\n",
      "Delta F = 15.87828492392808\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.1\n",
      "librarian 0.25\n",
      "sheriff 0.15384615384615385\n",
      "receptionist 0.2727272727272727\n",
      "nurse 0.3333333333333333\n",
      "cook 0.07692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.0\n",
      "cashier 0.375\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.0\n",
      "secretary 0.0\n",
      "developer 0.0\n",
      "manager 0.3333333333333333\n",
      "accountant 0.2\n",
      "salesperson 0.0\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.09090909090909091\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.2857142857142857\n",
      "lawyer 0.14285714285714285\n",
      "attendant 0.0\n",
      "physician 0.0\n",
      "designer 0.25\n",
      "carpenter 0.0\n",
      "hairdresser 0.375\n",
      "chief 0.0\n",
      "mover 0.0\n",
      "writer 0.1\n",
      "counselor 0.14285714285714285\n",
      "guard 0.1\n",
      "editor 0.08333333333333333\n",
      "supervisor 0.2\n",
      "laborer 0.16666666666666666\n",
      "housekeeper 0.6\n",
      "%%%%%%%%%%%%%%%%%%%%%%% DistilBERT %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 86 : 288\n",
      "accuracy_pro =  48.93048128342246\n",
      "accuracy_ant =  51.06951871657755\n",
      "Delta acc = -2.1390374331550888\n",
      "f1 pro M = 59.619450317124745\n",
      "f1 ant M = 61.63522012578616\n",
      "Delta M = -2.0157698086614175\n",
      "f1 pro F = 30.545454545454543\n",
      "f1 ant F = 32.47232472324724\n",
      "Delta F = -1.926870177792697\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.14285714285714285\n",
      "sheriff 0.25\n",
      "receptionist 1.0\n",
      "nurse 1.0\n",
      "cook 0.7692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.5\n",
      "cashier 0.0\n",
      "mechanic 0.125\n",
      "construction worker 0.16666666666666666\n",
      "tailor 0.0\n",
      "secretary 0.14285714285714285\n",
      "developer 0.25\n",
      "manager 0.2857142857142857\n",
      "accountant 0.0\n",
      "salesperson 0.4444444444444444\n",
      "driver 0.1111111111111111\n",
      "baker 0.0\n",
      "analyst 0.2222222222222222\n",
      "cleaner 0.09090909090909091\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.2857142857142857\n",
      "attendant 0.07142857142857142\n",
      "physician 0.2222222222222222\n",
      "designer 0.0\n",
      "carpenter 0.07692307692307693\n",
      "hairdresser 0.25\n",
      "chief 0.1\n",
      "mover 0.25\n",
      "writer 0.3333333333333333\n",
      "counselor 0.14285714285714285\n",
      "guard 0.0\n",
      "editor 0.16666666666666666\n",
      "supervisor 0.2\n",
      "laborer 0.0\n",
      "housekeeper 1.0\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 39 : 352\n",
      "accuracy_pro =  48.33759590792839\n",
      "accuracy_ant =  51.66240409207161\n",
      "Delta acc = -3.3248081841432224\n",
      "f1 pro M = 63.003663003663\n",
      "f1 ant M = 65.3211009174312\n",
      "Delta M = -2.3174379137681953\n",
      "f1 pro F = 14.40677966101695\n",
      "f1 ant F = 20.253164556962027\n",
      "Delta F = -5.846384895945077\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.1\n",
      "librarian 0.0\n",
      "sheriff 0.07692307692307693\n",
      "receptionist 0.36363636363636365\n",
      "nurse 0.2222222222222222\n",
      "cook 0.23076923076923078\n",
      "farmer 0.0\n",
      "janitor 0.15384615384615385\n",
      "cashier 0.0\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.08333333333333333\n",
      "secretary 0.125\n",
      "developer 0.125\n",
      "manager 0.5\n",
      "accountant 0.0\n",
      "salesperson 0.3\n",
      "driver 0.09090909090909091\n",
      "baker 0.0\n",
      "analyst 0.1\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.07142857142857142\n",
      "attendant 0.07142857142857142\n",
      "physician 0.1111111111111111\n",
      "designer 0.25\n",
      "carpenter 0.0\n",
      "hairdresser 0.0\n",
      "chief 0.1\n",
      "mover 0.1\n",
      "writer 0.0\n",
      "counselor 0.0\n",
      "guard 0.2\n",
      "editor 0.0\n",
      "supervisor 0.1\n",
      "laborer 0.0\n",
      "housekeeper 0.5\n",
      "%%%%%%%%%%%%%%%%%%%%%%% DistilBERT-O %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 82 : 292\n",
      "accuracy_pro =  52.67379679144385\n",
      "accuracy_ant =  47.32620320855615\n",
      "Delta acc = 5.347593582887697\n",
      "f1 pro M = 62.893081761006286\n",
      "f1 ant M = 59.043659043659034\n",
      "Delta M = 3.8494227173472524\n",
      "f1 pro F = 34.68634686346863\n",
      "f1 ant F = 26.217228464419474\n",
      "Delta F = 8.469118399049155\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.1\n",
      "librarian 0.2857142857142857\n",
      "sheriff 0.25\n",
      "receptionist 1.0\n",
      "nurse 0.875\n",
      "cook 0.5384615384615384\n",
      "farmer 0.0\n",
      "janitor 0.16666666666666666\n",
      "cashier 0.0\n",
      "mechanic 0.125\n",
      "construction worker 0.0\n",
      "tailor 0.07692307692307693\n",
      "secretary 0.2857142857142857\n",
      "developer 0.125\n",
      "manager 0.2857142857142857\n",
      "accountant 0.0\n",
      "salesperson 0.4444444444444444\n",
      "driver 0.2222222222222222\n",
      "baker 0.0\n",
      "analyst 0.1111111111111111\n",
      "cleaner 0.09090909090909091\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.2857142857142857\n",
      "attendant 0.07142857142857142\n",
      "physician 0.2222222222222222\n",
      "designer 0.0\n",
      "carpenter 0.07692307692307693\n",
      "hairdresser 0.25\n",
      "chief 0.1\n",
      "mover 0.25\n",
      "writer 0.3333333333333333\n",
      "counselor 0.2857142857142857\n",
      "guard 0.0\n",
      "editor 0.16666666666666666\n",
      "supervisor 0.2\n",
      "laborer 0.0\n",
      "housekeeper 1.0\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 25 : 366\n",
      "accuracy_pro =  48.84910485933504\n",
      "accuracy_ant =  51.150895140664964\n",
      "Delta acc = -2.3017902813299216\n",
      "f1 pro M = 64.28571428571429\n",
      "f1 ant M = 65.83184257602862\n",
      "Delta M = -1.5461282903143285\n",
      "f1 pro F = 9.909909909909908\n",
      "f1 ant F = 14.349775784753364\n",
      "Delta F = -4.439865874843456\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.1\n",
      "librarian 0.0\n",
      "sheriff 0.07692307692307693\n",
      "receptionist 0.2727272727272727\n",
      "nurse 0.1111111111111111\n",
      "cook 0.07692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.07692307692307693\n",
      "cashier 0.0\n",
      "mechanic 0.1\n",
      "construction worker 0.0\n",
      "tailor 0.08333333333333333\n",
      "secretary 0.125\n",
      "developer 0.0\n",
      "manager 0.5\n",
      "accountant 0.0\n",
      "salesperson 0.1\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.1\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.07142857142857142\n",
      "attendant 0.0\n",
      "physician 0.1111111111111111\n",
      "designer 0.25\n",
      "carpenter 0.0\n",
      "hairdresser 0.0\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.0\n",
      "counselor 0.0\n",
      "guard 0.1\n",
      "editor 0.0\n",
      "supervisor 0.1\n",
      "laborer 0.0\n",
      "housekeeper 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%% BERT-large %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 49 : 325\n",
      "accuracy_pro =  54.01069518716578\n",
      "accuracy_ant =  45.98930481283423\n",
      "Delta acc = 8.021390374331553\n",
      "f1 pro M = 66.27450980392156\n",
      "f1 ant M = 60.70038910505836\n",
      "Delta M = 5.574120698863197\n",
      "f1 pro F = 27.73109243697479\n",
      "f1 ant F = 13.675213675213676\n",
      "Delta F = 14.055878761761115\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.1\n",
      "librarian 0.0\n",
      "sheriff 0.08333333333333333\n",
      "receptionist 0.7272727272727273\n",
      "nurse 0.875\n",
      "cook 0.07692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.16666666666666666\n",
      "cashier 0.0\n",
      "mechanic 0.0\n",
      "construction worker 0.16666666666666666\n",
      "tailor 0.0\n",
      "secretary 0.7142857142857143\n",
      "developer 0.125\n",
      "manager 0.0\n",
      "accountant 0.0\n",
      "salesperson 0.4444444444444444\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.07142857142857142\n",
      "physician 0.2222222222222222\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.0\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.1111111111111111\n",
      "counselor 0.07142857142857142\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.3\n",
      "laborer 0.0\n",
      "housekeeper 0.9\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 52 : 339\n",
      "accuracy_pro =  57.289002557544755\n",
      "accuracy_ant =  42.710997442455245\n",
      "Delta acc = 14.57800511508951\n",
      "f1 pro M = 68.66791744840525\n",
      "f1 ant M = 57.894736842105274\n",
      "Delta M = 10.773180606299974\n",
      "f1 pro F = 32.93172690763053\n",
      "f1 ant F = 10.4\n",
      "Delta F = 22.531726907630528\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.0\n",
      "sheriff 0.0\n",
      "receptionist 0.9090909090909091\n",
      "nurse 0.8888888888888888\n",
      "cook 0.07692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.15384615384615385\n",
      "cashier 0.25\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.0\n",
      "secretary 0.875\n",
      "developer 0.0\n",
      "manager 0.16666666666666666\n",
      "accountant 0.0\n",
      "salesperson 0.4\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.1\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.0\n",
      "physician 0.0\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.0\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.0\n",
      "counselor 0.42857142857142855\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.1\n",
      "laborer 0.0\n",
      "housekeeper 0.8\n",
      "%%%%%%%%%%%%%%%%%%%%%%% BERT-large-O %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 53 : 321\n",
      "accuracy_pro =  55.61497326203209\n",
      "accuracy_ant =  44.38502673796791\n",
      "Delta acc = 11.229946524064175\n",
      "f1 pro M = 67.19367588932805\n",
      "f1 ant M = 59.21568627450981\n",
      "Delta M = 7.977989614818242\n",
      "f1 pro F = 31.40495867768595\n",
      "f1 ant F = 12.605042016806726\n",
      "Delta F = 18.799916660879227\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.1\n",
      "librarian 0.0\n",
      "sheriff 0.08333333333333333\n",
      "receptionist 0.9090909090909091\n",
      "nurse 0.875\n",
      "cook 0.07692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.08333333333333333\n",
      "cashier 0.125\n",
      "mechanic 0.0\n",
      "construction worker 0.16666666666666666\n",
      "tailor 0.0\n",
      "secretary 0.7142857142857143\n",
      "developer 0.125\n",
      "manager 0.0\n",
      "accountant 0.0\n",
      "salesperson 0.5555555555555556\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.14285714285714285\n",
      "physician 0.1111111111111111\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.0\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.1111111111111111\n",
      "counselor 0.14285714285714285\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.3\n",
      "laborer 0.0\n",
      "housekeeper 0.9\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 45 : 346\n",
      "accuracy_pro =  58.05626598465473\n",
      "accuracy_ant =  41.94373401534527\n",
      "Delta acc = 16.112531969309458\n",
      "f1 pro M = 69.62962962962962\n",
      "f1 ant M = 57.88497217068647\n",
      "Delta M = 11.744657458943152\n",
      "f1 pro F = 32.231404958677686\n",
      "f1 ant F = 6.584362139917695\n",
      "Delta F = 25.647042818759992\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.0\n",
      "sheriff 0.0\n",
      "receptionist 0.9090909090909091\n",
      "nurse 0.7777777777777778\n",
      "cook 0.07692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.07692307692307693\n",
      "cashier 0.125\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.0\n",
      "secretary 0.875\n",
      "developer 0.0\n",
      "manager 0.16666666666666666\n",
      "accountant 0.0\n",
      "salesperson 0.1\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.0\n",
      "physician 0.0\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.0\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.0\n",
      "counselor 0.42857142857142855\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.1\n",
      "laborer 0.0\n",
      "housekeeper 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%% BERT-base-multilingual %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 27 : 347\n",
      "accuracy_pro =  50.80213903743316\n",
      "accuracy_ant =  49.19786096256685\n",
      "Delta acc = 1.6042780748663077\n",
      "f1 pro M = 65.41353383458647\n",
      "f1 ant M = 64.55223880597015\n",
      "Delta M = 0.8612950286163255\n",
      "f1 pro F = 14.814814814814813\n",
      "f1 ant F = 10.377358490566039\n",
      "Delta F = 4.437456324248775\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.0\n",
      "sheriff 0.08333333333333333\n",
      "receptionist 0.18181818181818182\n",
      "nurse 1.0\n",
      "cook 0.3076923076923077\n",
      "farmer 0.0\n",
      "janitor 0.16666666666666666\n",
      "cashier 0.0\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.07692307692307693\n",
      "secretary 0.0\n",
      "developer 0.125\n",
      "manager 0.0\n",
      "accountant 0.0\n",
      "salesperson 0.1111111111111111\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.07142857142857142\n",
      "attendant 0.07142857142857142\n",
      "physician 0.0\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.375\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.1111111111111111\n",
      "counselor 0.0\n",
      "guard 0.0\n",
      "editor 0.0\n",
      "supervisor 0.0\n",
      "laborer 0.0\n",
      "housekeeper 0.0\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 33 : 358\n",
      "accuracy_pro =  53.452685421994886\n",
      "accuracy_ant =  46.547314578005114\n",
      "Delta acc = 6.905370843989772\n",
      "f1 pro M = 67.02898550724638\n",
      "f1 ant M = 62.06896551724138\n",
      "Delta M = 4.960019990004994\n",
      "f1 pro F = 20.869565217391305\n",
      "f1 ant F = 9.523809523809524\n",
      "Delta F = 11.345755693581781\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.0\n",
      "sheriff 0.0\n",
      "receptionist 0.2727272727272727\n",
      "nurse 1.0\n",
      "cook 0.3076923076923077\n",
      "farmer 0.0\n",
      "janitor 0.07692307692307693\n",
      "cashier 0.0\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.0\n",
      "secretary 0.125\n",
      "developer 0.0\n",
      "manager 0.0\n",
      "accountant 0.0\n",
      "salesperson 0.0\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.1\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.14285714285714285\n",
      "physician 0.0\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.625\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.0\n",
      "counselor 0.0\n",
      "guard 0.2\n",
      "editor 0.0\n",
      "supervisor 0.0\n",
      "laborer 0.0\n",
      "housekeeper 0.4\n",
      "%%%%%%%%%%%%%%%%%%%%%%% BERT-base-multilingual-O %%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "####################### Dataset test1 #####################\n",
      "Running on 374 examples\n",
      "number of male vs female predictions 39 : 335\n",
      "accuracy_pro =  52.406417112299465\n",
      "accuracy_ant =  47.593582887700535\n",
      "Delta acc = 4.81283422459893\n",
      "f1 pro M = 65.76923076923077\n",
      "f1 ant M = 62.59541984732825\n",
      "Delta M = 3.173810921902522\n",
      "f1 pro F = 21.929824561403507\n",
      "f1 ant F = 12.5\n",
      "Delta F = 9.429824561403507\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.2\n",
      "librarian 0.0\n",
      "sheriff 0.08333333333333333\n",
      "receptionist 0.18181818181818182\n",
      "nurse 0.875\n",
      "cook 0.23076923076923078\n",
      "farmer 0.0\n",
      "janitor 0.08333333333333333\n",
      "cashier 0.0\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.07692307692307693\n",
      "secretary 0.2857142857142857\n",
      "developer 0.125\n",
      "manager 0.0\n",
      "accountant 0.0\n",
      "salesperson 0.1111111111111111\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.14285714285714285\n",
      "physician 0.1111111111111111\n",
      "designer 0.0\n",
      "carpenter 0.07692307692307693\n",
      "hairdresser 0.5\n",
      "chief 0.1\n",
      "mover 0.0\n",
      "writer 0.2222222222222222\n",
      "counselor 0.0\n",
      "guard 0.2\n",
      "editor 0.08333333333333333\n",
      "supervisor 0.2\n",
      "laborer 0.0\n",
      "housekeeper 0.2\n",
      "####################### Dataset test2 #####################\n",
      "Running on 391 examples\n",
      "number of male vs female predictions 18 : 373\n",
      "accuracy_pro =  52.685421994884905\n",
      "accuracy_ant =  47.31457800511509\n",
      "Delta acc = 5.370843989769817\n",
      "f1 pro M = 67.3721340388007\n",
      "f1 ant M = 63.60424028268551\n",
      "Delta M = 3.7678937561151855\n",
      "f1 pro F = 13.953488372093027\n",
      "f1 ant F = 4.62962962962963\n",
      "Delta F = 9.323858742463397\n",
      "Female ratio of assignments per profession\n",
      "teacher 0.0\n",
      "librarian 0.0\n",
      "sheriff 0.0\n",
      "receptionist 0.0\n",
      "nurse 0.8888888888888888\n",
      "cook 0.07692307692307693\n",
      "farmer 0.0\n",
      "janitor 0.0\n",
      "cashier 0.0\n",
      "mechanic 0.0\n",
      "construction worker 0.0\n",
      "tailor 0.0\n",
      "secretary 0.125\n",
      "developer 0.0\n",
      "manager 0.16666666666666666\n",
      "accountant 0.0\n",
      "salesperson 0.0\n",
      "driver 0.0\n",
      "baker 0.0\n",
      "analyst 0.0\n",
      "cleaner 0.0\n",
      "auditor 0.0\n",
      "CEO 0.0\n",
      "assistant 0.0\n",
      "clerk 0.0\n",
      "lawyer 0.0\n",
      "attendant 0.07142857142857142\n",
      "physician 0.0\n",
      "designer 0.0\n",
      "carpenter 0.0\n",
      "hairdresser 0.25\n",
      "chief 0.0\n",
      "mover 0.0\n",
      "writer 0.0\n",
      "counselor 0.0\n",
      "guard 0.1\n",
      "editor 0.0\n",
      "supervisor 0.0\n",
      "laborer 0.0\n",
      "housekeeper 0.3\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "automated = True # set to true for all results, but for demo bit of overkill\n",
    "baseline_tester = False # Test baseline performance (Alice and Bob system, see Section 5.1 of report)\n",
    "\n",
    "if automated: # run for all out-of-the-box methods\n",
    "  which_berts = ['BERT', 'RoBERTa', 'DistilBERT', 'BERT-large', 'BERT-base-multilingual',]\n",
    "  online_skew_mit_methods_to_use = ['','-O'] # normal method and online method (denoted by -O suffix)\n",
    "#   online_skew_mit_methods_to_use = [''] # Do not use skew mitigation method\n",
    "  datasets = ['test1','test2']\n",
    "  \n",
    "else: #manually select one model and settings\n",
    "  which_berts = ['BERT']\n",
    "  online_skew_mit_methods_to_use = [''] # Do not use skew mitigation method\n",
    "#   datasets = ['test1','test2']\n",
    "  datasets = ['test2']\n",
    "\n",
    "\n",
    "\n",
    "for which_bert in which_berts:\n",
    "  model, tokenizer, mask_token = model_loader(which_bert)\n",
    "  for online_skew_mit, online_skew_string in enumerate(online_skew_mit_methods_to_use):\n",
    "    print('%%%%%%%%%%%%%%%%%%%%%%%', which_bert + online_skew_string , '%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "    results.append([which_bert+'-'+online_skew_string])\n",
    "    for dataset in datasets:\n",
    "      print('####################### Dataset '+dataset+' #####################')\n",
    "      labels, professions, sentiments = data_formatter(dataset, mask_token = mask_token,  baseline_tester = baseline_tester, reverse = True)\n",
    "      \n",
    "      df_pred, n_mist, n_misk_profs = predict(dataset,labels, professions, model, tokenizer, mask_token, verbose = False, online_skew_mit = online_skew_mit , use_elmo = 0)\n",
    "      \n",
    "      df_pred['Sentiment'] = sentiments[:,2]\n",
    "      labels = df_pred['True Label'].str.contains(\"she|her\") == False\n",
    "      \n",
    "      \n",
    "      #predicted = 2-df_pred['Top [MASK] Prediction'].str.contains(\"she|her\")-df_pred['Top [MASK] Prediction'].str.contains(\"he|his|him\") # 0 if female, 1 if male, 2 if neither\n",
    "      \n",
    "      predicted_mf = df_pred['Male Probability'] > df_pred['Female Probability']\n",
    "      \n",
    "      # print number of predictions per gender\n",
    "      print(\"number of male vs female predictions\", n_mist[1],':',n_mist[0])\n",
    "\n",
    "      f1_pro = f1_score(labels,predicted_mf)*100\n",
    "      f1_ant = f1_score(labels==False, predicted_mf)*100\n",
    "      accuracy_pro = accuracy_score(labels, predicted_mf)*100\n",
    "      accuracy_ant = accuracy_score(labels==False, predicted_mf)*100\n",
    "      \n",
    "      f1_pro_F = f1_score(labels==False,predicted_mf==False)*100\n",
    "      f1_ant_F = f1_score(labels, predicted_mf==False)*100\n",
    "\n",
    "\n",
    "      print('accuracy_pro = ', accuracy_pro)\n",
    "      print('accuracy_ant = ', accuracy_ant)\n",
    "      print('Delta acc =',accuracy_pro-accuracy_ant)\n",
    "      print('f1 pro M =',f1_pro)\n",
    "      print('f1 ant M =',f1_ant)\n",
    "      print('Delta M =',f1_pro-f1_ant)\n",
    "      print('f1 pro F =',f1_pro_F)\n",
    "      print('f1 ant F =',f1_ant_F)\n",
    "      print('Delta F =',f1_pro_F-f1_ant_F)\n",
    "      stereo = (abs(f1_pro-f1_ant)+abs(f1_pro_F-f1_ant_F))/2\n",
    "      skew = (abs(f1_pro-f1_pro_F)+abs(f1_ant-f1_ant_F))/2\n",
    "      results[-1] +=[round(f1_pro,1),round(f1_ant,1),round(f1_pro_F,1),round(f1_ant_F,1), round(stereo,1), round(skew,1)]\n",
    "      # prints the dictionary of professions with number of times \n",
    "      print('Female ratio of assignments per profession')\n",
    "      for prof in n_misk_profs.keys():\n",
    "        print(prof, n_misk_profs[prof][1]/(n_misk_profs[prof][1]+n_misk_profs[prof][0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtGZiPxLzUBo"
   },
   "source": [
    "Code for creating tables (and LaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "ndTcaO6y-ISG",
    "outputId": "214309f2-32ff-4370-ba86-862c6528debc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Model  T1: pro M  T1: anti M  T1: pro F  T1: anti F\n",
      "0                      BERT-       62.6        61.3       29.3        25.1\n",
      "1                    BERT--O       63.9        59.3       33.5        23.2\n",
      "2                   RoBERTa-       65.5        53.8       44.6        24.0\n",
      "3                 RoBERTa--O       49.9        39.9       58.9        49.6\n",
      "4                DistilBERT-       59.6        61.6       30.5        32.5\n",
      "5              DistilBERT--O       62.9        59.0       34.7        26.2\n",
      "6                BERT-large-       66.3        60.7       27.7        13.7\n",
      "7              BERT-large--O       67.2        59.2       31.4        12.6\n",
      "8    BERT-base-multilingual-       65.4        64.6       14.8        10.4\n",
      "9  BERT-base-multilingual--O       65.8        62.6       21.9        12.5\n",
      "                       Model  T2: pro M  T2: anti M  T2: pro F  T2: anti F\n",
      "0                      BERT-       66.4        58.9       31.8        17.0\n",
      "1                    BERT--O       68.2        58.1       32.7        11.9\n",
      "2                   RoBERTa-       62.9        27.0       69.0        39.3\n",
      "3                 RoBERTa--O       67.5        60.3       26.7        10.8\n",
      "4                DistilBERT-       63.0        65.3       14.4        20.3\n",
      "5              DistilBERT--O       64.3        65.8        9.9        14.3\n",
      "6                BERT-large-       68.7        57.9       32.9        10.4\n",
      "7              BERT-large--O       69.6        57.9       32.2         6.6\n",
      "8    BERT-base-multilingual-       67.0        62.1       20.9         9.5\n",
      "9  BERT-base-multilingual--O       67.4        63.6       14.0         4.6\n",
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "                     Model &  T1: pro M &  T1: anti M &  T1: pro F &  T1: anti F &  T1: stereo &  T1: skew &  T2: pro M &  T2: anti M &  T2: pro F &  T2: anti F &  T2: stereo &  T2: skew \\\\\n",
      "\\midrule\n",
      "                     BERT- &       62.6 &        61.3 &       29.3 &        25.1 &         2.8 &      34.7 &       66.4 &        58.9 &       31.8 &        17.0 &        11.2 &      38.3 \\\\\n",
      "                   BERT--O &       63.9 &        59.3 &       33.5 &        23.2 &         7.5 &      33.3 &       68.2 &        58.1 &       32.7 &        11.9 &        15.4 &      40.9 \\\\\n",
      "                  RoBERTa- &       65.5 &        53.8 &       44.6 &        24.0 &        16.2 &      25.3 &       62.9 &        27.0 &       69.0 &        39.3 &        32.8 &       9.2 \\\\\n",
      "                RoBERTa--O &       49.9 &        39.9 &       58.9 &        49.6 &         9.6 &       9.4 &       67.5 &        60.3 &       26.7 &        10.8 &        11.6 &      45.2 \\\\\n",
      "               DistilBERT- &       59.6 &        61.6 &       30.5 &        32.5 &         2.0 &      29.1 &       63.0 &        65.3 &       14.4 &        20.3 &         4.1 &      46.8 \\\\\n",
      "             DistilBERT--O &       62.9 &        59.0 &       34.7 &        26.2 &         6.2 &      30.5 &       64.3 &        65.8 &        9.9 &        14.3 &         3.0 &      52.9 \\\\\n",
      "               BERT-large- &       66.3 &        60.7 &       27.7 &        13.7 &         9.8 &      42.8 &       68.7 &        57.9 &       32.9 &        10.4 &        16.7 &      41.6 \\\\\n",
      "             BERT-large--O &       67.2 &        59.2 &       31.4 &        12.6 &        13.4 &      41.2 &       69.6 &        57.9 &       32.2 &         6.6 &        18.7 &      44.3 \\\\\n",
      "   BERT-base-multilingual- &       65.4 &        64.6 &       14.8 &        10.4 &         2.6 &      52.4 &       67.0 &        62.1 &       20.9 &         9.5 &         8.2 &      49.4 \\\\\n",
      " BERT-base-multilingual--O &       65.8 &        62.6 &       21.9 &        12.5 &         6.3 &      47.0 &       67.4 &        63.6 &       14.0 &         4.6 &         6.5 &      56.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try: # if T1 and T2 is used\n",
    "  resultdf = pd.DataFrame(results, columns = ['Model', 'T1: pro M', 'T1: anti M', 'T1: pro F', 'T1: anti F', 'T1: stereo', 'T1: skew', 'T2: pro M', 'T2: anti M', 'T2: pro F', 'T2: anti F', 'T2: stereo', 'T2: skew'])\n",
    "  resultdf1 = resultdf[['Model', 'T1: pro M', 'T1: anti M', 'T1: pro F', 'T1: anti F']]\n",
    "  print(resultdf1)\n",
    "  resultdf2 = resultdf[['Model', 'T2: pro M', 'T2: anti M', 'T2: pro F', 'T2: anti F']]\n",
    "  print(resultdf2)\n",
    "  ## print as latex output\n",
    "  print(resultdf.to_latex(index=False))\n",
    "except: # If just T2 is used\n",
    "  resultdf = pd.DataFrame(results, columns = ['Model', 'T2: pro M', 'T2: anti M', 'T2: pro F', 'T2: anti F', 'T2: stereo', 'T2: skew'])\n",
    "  resultdf2 = resultdf[['Model', 'T2: pro M', 'T2: anti M', 'T2: pro F', 'T2: anti F']]\n",
    "  print(resultdf2)\n",
    "  ## print as latex output\n",
    "  print(resultdf.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
