{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from src.metrics import seat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pieterdelobelle/Downloads/fairness-correlation-codes/.env/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py:698: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, AutoModelWithLMHead\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaskedLMOutput' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3cf6ec694e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"This is the _.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseat_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/fairness-correlation-codes/src/metrics/seat.py\u001b[0m in \u001b[0;36mseat_test\u001b[0;34m(attribute_template, target_template, tokenizer, model)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \"\"\"\n\u001b[1;32m    294\u001b[0m     return test(\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mattribute_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddingType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/fairness-correlation-codes/src/metrics/seat.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(attribute_template, target_template, tokenizer, model, embedding_type)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mattribute_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         )\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     }\n\u001b[1;32m    241\u001b[0m     Y = {\n",
      "\u001b[0;32m~/Downloads/fairness-correlation-codes/src/metrics/seat.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mattribute_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         )\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     }\n\u001b[1;32m    241\u001b[0m     Y = {\n",
      "\u001b[0;32m~/Downloads/fairness-correlation-codes/src/metrics/seat.py\u001b[0m in \u001b[0;36msentence_embedding\u001b[0;34m(template, word, embedding_type, tokenizer, model)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaskedLMOutput' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "\n",
    "attribute_template = \"This is the _.\"\n",
    "target_template = \"This is the _.\"\n",
    "\n",
    "print(seat.seat_test(attribute_template, target_template, tokenizer, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8712208646044697, 1: 1.058285319386308, 2: 1.3139517070717035, 3: 0.8155197844164715, 4: 1.3221400790178275, 5: 0.9451985484852444, 6: 0.9105467860940959, 7: 1.4382343005457392, 8: 0.9077465293875092, 9: 1.173698640973059, 10: 0.8851261243220466, 11: 1.2028881070832158, 12: 0.9902692981089054, 13: 1.1613303128006802, 14: 1.2099159345422645, 15: 0.7557550213993255, 16: 0.7922075649555417, 17: 1.0890842309441016, 18: 0.88942015184123, 19: 0.8198238074423987}\n"
     ]
    }
   ],
   "source": [
    "print(seat.lauscher_et_al_test(attribute_template, target_template, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.7236307836559362, 1: 0.735665249491224, 2: 1.190387358510162, 3: 0.6466443393922682, 4: 1.2353762496799099, 5: 0.9062731457484468, 6: 0.8668005790616289, 7: 1.021647268318636, 8: 0.7815163111358471, 9: 0.9549401853143625, 10: 0.9440463847337583, 11: 0.9411252904925845, 12: 1.0025084528225345, 13: 0.897598538114084, 14: 0.8395899204861828, 15: 0.5940909068049024, 16: 0.8911453081035888, 17: 0.7167719098601603, 18: 0.8188156742195554, 19: 0.43772511354757954}\n"
     ]
    }
   ],
   "source": [
    "print(seat.tan_et_al_test(attribute_template, target_template, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import lpbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_fill_bias</th>\n",
       "      <th>gender_fill_prior_correction</th>\n",
       "      <th>gender_fill_bias_prior_corrected</th>\n",
       "      <th>target_fill_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>226.000000</td>\n",
       "      <td>2.260000e+02</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.353317</td>\n",
       "      <td>3.325582e-09</td>\n",
       "      <td>1.155734</td>\n",
       "      <td>-0.479219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.256272</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.718079</td>\n",
       "      <td>0.171471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.860509</td>\n",
       "      <td>3.325582e-09</td>\n",
       "      <td>-4.425986</td>\n",
       "      <td>-1.031234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.143960</td>\n",
       "      <td>3.325582e-09</td>\n",
       "      <td>0.822944</td>\n",
       "      <td>-0.521749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.414399</td>\n",
       "      <td>3.325582e-09</td>\n",
       "      <td>1.190396</td>\n",
       "      <td>-0.521749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.531820</td>\n",
       "      <td>3.325582e-09</td>\n",
       "      <td>1.568748</td>\n",
       "      <td>-0.521749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.856755</td>\n",
       "      <td>3.325582e-09</td>\n",
       "      <td>2.795320</td>\n",
       "      <td>0.595716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender_fill_bias  gender_fill_prior_correction  \\\n",
       "count        226.000000                  2.260000e+02   \n",
       "mean           0.353317                  3.325582e-09   \n",
       "std            0.256272                  0.000000e+00   \n",
       "min           -0.860509                  3.325582e-09   \n",
       "25%            0.143960                  3.325582e-09   \n",
       "50%            0.414399                  3.325582e-09   \n",
       "75%            0.531820                  3.325582e-09   \n",
       "max            0.856755                  3.325582e-09   \n",
       "\n",
       "       gender_fill_bias_prior_corrected  target_fill_bias  \n",
       "count                        226.000000        226.000000  \n",
       "mean                           1.155734         -0.479219  \n",
       "std                            0.718079          0.171471  \n",
       "min                           -4.425986         -1.031234  \n",
       "25%                            0.822944         -0.521749  \n",
       "50%                            1.190396         -0.521749  \n",
       "75%                            1.568748         -0.521749  \n",
       "max                            2.795320          0.595716  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpbs.lpbs_test(\"\",\"\", tokenizer, model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e94ad2f0a869c7a0d4fd2f25322f5fcfa75a94c6b344072802a64a2c890d2c64"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
